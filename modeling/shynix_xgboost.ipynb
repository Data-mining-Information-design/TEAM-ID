{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance, plot_tree\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "mm = MinMaxScaler()\n",
    "ss = StandardScaler()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2670 entries, 2010-07-19 to 2021-05-14\n",
      "Data columns (total 34 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   삼성등락       2670 non-null   int64  \n",
      " 1   종가         2670 non-null   float64\n",
      " 2   거래량        2670 non-null   int64  \n",
      " 3   거래대금       2670 non-null   float64\n",
      " 4   시가총액       2670 non-null   float64\n",
      " 5   상장주식수      2670 non-null   int64  \n",
      " 6   환율         2670 non-null   float64\n",
      " 7   유가종가       2670 non-null   float64\n",
      " 8   유가오픈       2670 non-null   float64\n",
      " 9   유가고가       2670 non-null   float64\n",
      " 10  유가저가       2670 non-null   float64\n",
      " 11  유가변동률      2670 non-null   float64\n",
      " 12  한국은행기준금리   2670 non-null   float64\n",
      " 13  연준기준금리     2670 non-null   float64\n",
      " 14  한미기준금리차이   2670 non-null   float64\n",
      " 15  반도체수출금액지수  2661 non-null   float64\n",
      " 16  삼성종가       2670 non-null   float64\n",
      " 17  SOX종가      2670 non-null   float64\n",
      " 18  SOX변동률     2670 non-null   float64\n",
      " 19  BTC종가      2670 non-null   float64\n",
      " 20  BTC변동률     2670 non-null   float64\n",
      " 21  종가코스피      2670 non-null   float64\n",
      " 22  고가코스피      2670 non-null   float64\n",
      " 23  저가코스피      2670 non-null   float64\n",
      " 24  거래량코스피     2670 non-null   float64\n",
      " 25  코스피변동      2670 non-null   float64\n",
      " 26  종가코스닥      2670 non-null   float64\n",
      " 27  시가코스닥      2670 non-null   float64\n",
      " 28  고가코스닥      2670 non-null   float64\n",
      " 29  저가코스닥      2670 non-null   float64\n",
      " 30  거래량코스닥     2670 non-null   float64\n",
      " 31  변동코스닥      2670 non-null   float64\n",
      " 32  S.P종가      2670 non-null   float64\n",
      " 33  S.P변동률     2670 non-null   float64\n",
      "dtypes: float64(31), int64(3)\n",
      "memory usage: 730.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#등락으로 분류를 시켰기 때문에 등락 퍼센트는 제거해 주었습니다.다른 변수와 상관성이 너무 높은 속성들은 제거처리 해주었습니다.\n",
    "df=pd.read_csv(r'C:\\DRworks\\shynix_short.csv',encoding='cp949', index_col=0)\n",
    "df=df.drop('등락분류',axis=1)\n",
    "df=df.drop('등락률',axis=1)\n",
    "df=df.drop('대비',axis=1)\n",
    "df=df.drop('등락지표',axis=1)\n",
    "df=df.drop('등락',axis=1)\n",
    "df=df.drop('시가',axis=1)\n",
    "df=df.drop('고가',axis=1)\n",
    "df=df.drop('저가',axis=1)\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xbbost를 위해 x y 로 데이터 분리 후 dmatrix로 변환 (y=등락정도)\n",
    "X, y = df.iloc[:,1:],df.iloc[:,0]\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2021)\n",
    "#시기로 분할할 때 데이터\n",
    "#split = \"2012-03-19\"\n",
    "#train = df[:split]\n",
    "#test= df[split:]\n",
    "\n",
    "#y_train = train.loc[:,'등락.분류']\n",
    "#X_train = train.drop('등락.분류', axis=1)\n",
    "#y_test = test.loc[:,'등락.분류']\n",
    "#X_test = test.drop('등락.분류', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\phythontemp\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:03:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs...\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             n_jobs=8,\n",
       "             param_grid={'gamma': [0, 1, 2], 'max_depth': [6, 7, 8, 9],\n",
       "                         'min_child_weight': [3, 4, 5],\n",
       "                         'n_estimators': [50, 100, 150, 200],\n",
       "                         'nthread': [3, 4, 5, 6],\n",
       "                         'random_state': [50, 100, 150, 200]},\n",
       "             return_train_score=True, scoring='roc_auc')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#시기로 분할할 때 데이터\n",
    "#split = \"2012-03-19\"\n",
    "#train = df[:split]\n",
    "#test= df[split:]\n",
    "\n",
    "#y_train = train.loc[:,'등락.분류']\n",
    "#X_train = train.drop('등락.분류', axis=1)\n",
    "#y_test = test.loc[:,'등락.분류']\n",
    "#X_test = test.drop('등락.분류', axis=1)\n",
    "\n",
    "# XGBoost 분류기 생성\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "\n",
    "#초모수 격자생성\n",
    "xgb_param_grid = {   \n",
    "                    \n",
    "                    'gamma':[0,1,2], \n",
    "                    'max_depth':[6,7,8,9], \n",
    "                    'min_child_weight':[3,4,5], \n",
    "                    'n_estimators':[50,100,150,200], \n",
    "                    'nthread':[3,4,5,6],                    \n",
    "                    'random_state':[50,100,150,200] \n",
    "                    }\n",
    "# GridSearchCV 객체 생성\n",
    "hr_grid = GridSearchCV(estimator=xgb_clf,\n",
    "                       param_grid=xgb_param_grid,\n",
    "                       scoring='roc_auc',\n",
    "                       n_jobs=8,\n",
    "                       cv=5,\n",
    "                       refit=True, \n",
    "                       return_train_score=True)\n",
    "hr_grid.fit(X_train, y_train)\n",
    "#model=XGBClassifier(booster='gbtree', \n",
    "                   # colsample_bylevel=0.9, \n",
    "                   # colsample_bytree=0.8, \n",
    "                   # gamma=0, \n",
    "                   # max_depth=8, \n",
    "                   # min_child_weight=4, \n",
    "                   # n_estimators=100, \n",
    "                   # nthread=4, \n",
    "                   # objective='multi:softprob', \n",
    "                   # random_state=150, \n",
    "                   # silent= True)\n",
    "\n",
    "#model.fit(X_train, y_train,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-3093fa8f89ba>, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-3093fa8f89ba>\"\u001b[1;36m, line \u001b[1;32m23\u001b[0m\n\u001b[1;33m    random_state:  \\t{random_state}'\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "## 최고성능\n",
    "best_score = hr_grid.best_score_\n",
    "# 최고성능을 내는 행을 찾아냄\n",
    "best_row = hr_grid.best_index_\n",
    "\n",
    "# 최적 초모수: max_depth, subsample\n",
    "best_max_depth     = hr_grid.best_params_[\"max_depth\"]\n",
    "best_max_gamma = hr_grid.best_params_[\"gamma\"]\n",
    "best_max_min_child_weight= hr_grid.best_params_[\"min_child_weight\"]\n",
    "best_max_n_estimators= hr_grid.best_params_[\"n_estimators\"]\n",
    "best_max_nthread= hr_grid.best_params_[\"nthread\"]\n",
    "best_max_random_state= hr_grid.best_params_[\"random_state\"]\n",
    "\n",
    "\n",
    "nl = '\\n'\n",
    "print(f 'AUC:  \\t {best_score:.6f}{nl}\\\n",
    "         index:           \\t {best_row}{nl}\\\n",
    "         max_depth:      \\t {max_depth}{nl}\\\n",
    "         gamma :    \\t{gamma}{nl}\\\n",
    "         min_child_weight: \\t{min_child_weight}{nl}\\\n",
    "         n_estimators:  \\t{n_estimators}{nl}\\\n",
    "         nthread :   \\t{nthread}{nl}\\\n",
    "         random_state:  \\t{random_state}'\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_nthread</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>0.617264</td>\n",
       "      <td>0.018154</td>\n",
       "      <td>0.005205</td>\n",
       "      <td>7.491184e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.820108</td>\n",
       "      <td>0.02742</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991415</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>0.995648</td>\n",
       "      <td>0.997696</td>\n",
       "      <td>0.995376</td>\n",
       "      <td>0.995647</td>\n",
       "      <td>0.002375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889</th>\n",
       "      <td>1.340723</td>\n",
       "      <td>0.068770</td>\n",
       "      <td>0.004805</td>\n",
       "      <td>4.001379e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.820108</td>\n",
       "      <td>0.02742</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991415</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>0.995648</td>\n",
       "      <td>0.997696</td>\n",
       "      <td>0.995376</td>\n",
       "      <td>0.995647</td>\n",
       "      <td>0.002375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>1.567031</td>\n",
       "      <td>0.099832</td>\n",
       "      <td>0.005205</td>\n",
       "      <td>4.003526e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.820108</td>\n",
       "      <td>0.02742</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991415</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>0.995648</td>\n",
       "      <td>0.997696</td>\n",
       "      <td>0.995376</td>\n",
       "      <td>0.995647</td>\n",
       "      <td>0.002375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>1.718773</td>\n",
       "      <td>0.066742</td>\n",
       "      <td>0.005202</td>\n",
       "      <td>4.019165e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.820108</td>\n",
       "      <td>0.02742</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991415</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>0.995648</td>\n",
       "      <td>0.997696</td>\n",
       "      <td>0.995376</td>\n",
       "      <td>0.995647</td>\n",
       "      <td>0.002375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>1.806155</td>\n",
       "      <td>0.068590</td>\n",
       "      <td>0.005205</td>\n",
       "      <td>7.490547e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.820108</td>\n",
       "      <td>0.02742</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991415</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>0.995648</td>\n",
       "      <td>0.997696</td>\n",
       "      <td>0.995376</td>\n",
       "      <td>0.995647</td>\n",
       "      <td>0.002375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.724677</td>\n",
       "      <td>0.005272</td>\n",
       "      <td>0.005205</td>\n",
       "      <td>4.004002e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806844</td>\n",
       "      <td>0.02810</td>\n",
       "      <td>2289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1.675430</td>\n",
       "      <td>0.023584</td>\n",
       "      <td>0.005005</td>\n",
       "      <td>9.536743e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806844</td>\n",
       "      <td>0.02810</td>\n",
       "      <td>2289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.667124</td>\n",
       "      <td>0.088899</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>4.909921e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806844</td>\n",
       "      <td>0.02810</td>\n",
       "      <td>2289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.458933</td>\n",
       "      <td>0.388948</td>\n",
       "      <td>0.005806</td>\n",
       "      <td>4.003525e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806844</td>\n",
       "      <td>0.02810</td>\n",
       "      <td>2289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1.709863</td>\n",
       "      <td>0.028679</td>\n",
       "      <td>0.005605</td>\n",
       "      <td>4.904270e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806844</td>\n",
       "      <td>0.02810</td>\n",
       "      <td>2289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2304 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1857       0.617264      0.018154         0.005205    7.491184e-04   \n",
       "1889       1.340723      0.068770         0.004805    4.001379e-04   \n",
       "1891       1.567031      0.099832         0.005205    4.003526e-04   \n",
       "1892       1.718773      0.066742         0.005202    4.019165e-04   \n",
       "1893       1.806155      0.068590         0.005205    7.490547e-04   \n",
       "...             ...           ...              ...             ...   \n",
       "53         1.724677      0.005272         0.005205    4.004002e-04   \n",
       "52         1.675430      0.023584         0.005005    9.536743e-08   \n",
       "51         1.667124      0.088899         0.005906    4.909921e-04   \n",
       "50         1.458933      0.388948         0.005806    4.003525e-04   \n",
       "63         1.709863      0.028679         0.005605    4.904270e-04   \n",
       "\n",
       "     param_gamma param_max_depth param_min_child_weight param_n_estimators  \\\n",
       "1857           2               7                      5                 50   \n",
       "1889           2               7                      5                150   \n",
       "1891           2               7                      5                150   \n",
       "1892           2               7                      5                150   \n",
       "1893           2               7                      5                150   \n",
       "...          ...             ...                    ...                ...   \n",
       "53             0               6                      3                200   \n",
       "52             0               6                      3                200   \n",
       "51             0               6                      3                200   \n",
       "50             0               6                      3                200   \n",
       "63             0               6                      3                200   \n",
       "\n",
       "     param_nthread param_random_state  ... mean_test_score  std_test_score  \\\n",
       "1857             3                100  ...        0.820108         0.02742   \n",
       "1889             3                100  ...        0.820108         0.02742   \n",
       "1891             3                200  ...        0.820108         0.02742   \n",
       "1892             4                 50  ...        0.820108         0.02742   \n",
       "1893             4                100  ...        0.820108         0.02742   \n",
       "...            ...                ...  ...             ...             ...   \n",
       "53               4                100  ...        0.806844         0.02810   \n",
       "52               4                 50  ...        0.806844         0.02810   \n",
       "51               3                200  ...        0.806844         0.02810   \n",
       "50               3                150  ...        0.806844         0.02810   \n",
       "63               6                200  ...        0.806844         0.02810   \n",
       "\n",
       "      rank_test_score  split0_train_score  split1_train_score  \\\n",
       "1857                1            0.991415              0.9981   \n",
       "1889                1            0.991415              0.9981   \n",
       "1891                1            0.991415              0.9981   \n",
       "1892                1            0.991415              0.9981   \n",
       "1893                1            0.991415              0.9981   \n",
       "...               ...                 ...                 ...   \n",
       "53               2289            1.000000              1.0000   \n",
       "52               2289            1.000000              1.0000   \n",
       "51               2289            1.000000              1.0000   \n",
       "50               2289            1.000000              1.0000   \n",
       "63               2289            1.000000              1.0000   \n",
       "\n",
       "      split2_train_score  split3_train_score  split4_train_score  \\\n",
       "1857            0.995648            0.997696            0.995376   \n",
       "1889            0.995648            0.997696            0.995376   \n",
       "1891            0.995648            0.997696            0.995376   \n",
       "1892            0.995648            0.997696            0.995376   \n",
       "1893            0.995648            0.997696            0.995376   \n",
       "...                  ...                 ...                 ...   \n",
       "53              1.000000            1.000000            1.000000   \n",
       "52              1.000000            1.000000            1.000000   \n",
       "51              1.000000            1.000000            1.000000   \n",
       "50              1.000000            1.000000            1.000000   \n",
       "63              1.000000            1.000000            1.000000   \n",
       "\n",
       "      mean_train_score  std_train_score  \n",
       "1857          0.995647         0.002375  \n",
       "1889          0.995647         0.002375  \n",
       "1891          0.995647         0.002375  \n",
       "1892          0.995647         0.002375  \n",
       "1893          0.995647         0.002375  \n",
       "...                ...              ...  \n",
       "53            1.000000         0.000000  \n",
       "52            1.000000         0.000000  \n",
       "51            1.000000         0.000000  \n",
       "50            1.000000         0.000000  \n",
       "63            1.000000         0.000000  \n",
       "\n",
       "[2304 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_grid_df = pd.DataFrame(hr_grid.cv_results_)\n",
    "hr_grid_df.loc[:,['mean_test_score', \"params\"]]\n",
    "hr_grid_df.sort_values(by=['mean_test_score'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "tree must be Booster, XGBModel or dict instance",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-fa2aa84835f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'font'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfamily\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Malgun Gothic'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"figure.figsize\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplot_importance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhr_grid_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\phythontemp\\lib\\site-packages\\xgboost\\plotting.py\u001b[0m in \u001b[0;36mplot_importance\u001b[1;34m(booster, ax, height, xlim, ylim, title, xlabel, ylabel, fmap, importance_type, max_num_features, grid, show_values, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mimportance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbooster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tree must be Booster, XGBModel or dict instance'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mimportance\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: tree must be Booster, XGBModel or dict instance"
     ]
    }
   ],
   "source": [
    "#변수 중요도 그래프\n",
    "plt.rc('font',family='Malgun Gothic')\n",
    "plt.rcParams[\"figure.figsize\"] = (10,7)\n",
    "plot_importance(hr_grid_df, height=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 예측\n",
    "#y_pred = model.predict(X_test)\n",
    "#y_true = y_test\n",
    "\n",
    "#acc = accuracy_score(y_true, y_pred)\n",
    "#con_mat = confusion_matrix(y_true, y_pred)\n",
    "#con_mat\n",
    "#report = classification_report(y_true, y_pred)\n",
    "#print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
